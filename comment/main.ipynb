{"cells":[{"cell_type":"code","execution_count":224,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2563,"status":"ok","timestamp":1657166626569,"user":{"displayName":"‎정민정(엘텍공과대학 소프트웨어학부)","userId":"10603764534365541111"},"user_tz":-540},"id":"KQ4xkq2pF7eY","outputId":"5ec3fc54-cb8c-4f77-e479-3a772f1a927a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":225,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1657166627510,"user":{"displayName":"‎정민정(엘텍공과대학 소프트웨어학부)","userId":"10603764534365541111"},"user_tz":-540},"id":"IIlHHayeGEme","outputId":"cb7e3415-1a3a-4331-d7ed-21a68140431f"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/KoGPT2-DiaryCommentAI/comment\n"]}],"source":["# 폴더 이동\n","%cd /content/drive/MyDrive/Colab Notebooks/comment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AyBsp4wXwEmB"},"outputs":[],"source":["!pip install -r requirements.txt\n","!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"markdown","metadata":{"id":"NestQk1UtCIi"},"source":["일기 문단 전체를 diary에 저장합니다."]},{"cell_type":"code","execution_count":226,"metadata":{"executionInfo":{"elapsed":399,"status":"ok","timestamp":1657166629760,"user":{"displayName":"‎정민정(엘텍공과대학 소프트웨어학부)","userId":"10603764534365541111"},"user_tz":-540},"id":"jj31TEljFgaP"},"outputs":[],"source":["diary = '어릴 적부터 태극기를 달아야 하는 날 3.1절, 제헌절, 광복절, 개천절, 한글날, 현충일 에는 아침에 일어나 국기부터 달았던 것 같다. 철저히 체크 하시는 우리 아버지. 당연스럽게도 결혼 후에 태극기를 주문했다. 나도 내 자녀들에게도 마음을 잘 심어주고 싶다는 생각이었다. 해야 하는 것이고 의미 있고 좋은 실천이다. 오늘은 조의를 표하는 현충일 이기에 조기를 달아야 하는데. 조기는 깃면의 넓이(세로) 만큼 내려 달아야 한다. 완전한 조기를 달 수 없으면 최대한 닿지 않게 내려서 달면 된다고 한다. 우리 집은 밑 부분이 최대한 잘 고정될 만큼의 안전한 선에서 달았다. 좋은 실천을 한 것 같아 마음이 뿌듯했다.'"]},{"cell_type":"markdown","metadata":{"id":"QnzkoSRwFgaX"},"source":["문장의 위치에 따라 중요도를 다르게 설정하였습니다.\n","일기이므로, 마지막 문장이 다른 문장보다 10배 중요하다고 가정하였습니다.\n","numpy.ndarray 형태로 bias 를 만든 다음, 이를 summarize 함수의 bias 에 입력하면 가장 먼저 맨 마지막 문장이 중요한 문장으로 선택됩니다. \n","다른 문장들 중에서도 맨 마지막 문장과 비슷할수록 상대적인 중요도가 더 커집니다."]},{"cell_type":"code","execution_count":227,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1657166631963,"user":{"displayName":"‎정민정(엘텍공과대학 소프트웨어학부)","userId":"10603764534365541111"},"user_tz":-540},"id":"Wyv38N5CFgaY","outputId":"a574943b-f366-4372-d9ec-14f08b4a09d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["['좋은 실천을 한 것 같아 마음이 뿌듯했다.', '1절, 제헌절, 광복절, 개천절, 한글날, 현충일 에는 아침에 일어나 국기부터 달았던 것 같다.', '해야 하는 것이고 의미 있고 좋은 실천이다.']\n"]}],"source":["import numpy as np\n","\n","sents_list = diary.split('.')\n","sents =[]\n","for sent in sents_list:\n","    if sent.strip() is not '':\n","      sents.append(sent.strip())\n","      \n","bias = np.ones(len(sents))\n","bias[-1] = 10\n","keysents_list = summarizer.summarize(sents, topk=3, bias=bias)\n","keysents = []\n","for _, _, sent in keysents_list:\n","    keysents.append(sent+'.')\n","\n","print(keysents)"]},{"cell_type":"code","execution_count":228,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11953,"status":"ok","timestamp":1657166645570,"user":{"displayName":"‎정민정(엘텍공과대학 소프트웨어학부)","userId":"10603764534365541111"},"user_tz":-540},"id":"wQkdXshDVhX9","outputId":"3529fb07-90ed-4e5b-85c4-bb4eb1c17eb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["좋은 실천이네요.\n"]}],"source":["import torch\n","from pytorch_lightning.core.lightning import LightningModule\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","\n","# KoGPT2 모델에서 사용하는 특수 토큰\n","U_TKN = '<usr>' # 일기 핵심 문장의 시작을 나타내는 특수 토큰\n","S_TKN = '<sys>' # 코멘트의 시작을 나타내는 특수 토큰\n","BOS = '</s>'    # 문장의 시작을 나타내는 특수 토큰\n","EOS = '</s>'    # 문장의 끝을 나타내는 특수 토큰\n","UNK = '<unk>'   # 어휘에 없는 토큰을 나타내는 특수 토큰\n","MASK = '<unused0>'  # 마스킹된 토큰을 나타내는 특수 토큰\n","SENT = '<unused1>'  # 일기 핵심 문장의 끝을 나타내는 특수 토큰\n","PAD = '<pad>'   # 토큰 배열을 동일한 크기로 만드는데 사용되는 특수 토큰\n","\n","# KoGPT2에서 제공하는 토큰나이저 사용\n","TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","            bos_token=BOS, eos_token=EOS, unk_token=UNK,\n","            pad_token=PAD, mask_token=MASK)\n","class KoGPT2Comment(LightningModule):\n","    def __init__(self, hparams, **kwargs):\n","        super(KoGPT2Comment, self).__init__()\n","        self.kogpt2 = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2') # pretrained KoGPT2 model\n","    def forward(self, inputs):\n","        # (batch, seq_len, hiddens)\n","        output = self.kogpt2(inputs, return_dict=True)\n","        return output.logits\n","    def comment(self, keysent):\n","        tok = TOKENIZER\n","        sent='0'\n","        sent_tokens = tok.tokenize(sent)\n","        with torch.no_grad():\n","                q = keysent\n","                a = ''\n","                while 1:\n","                    input_ids = torch.LongTensor(tok.encode(U_TKN + q + SENT + sent + S_TKN + a)).unsqueeze(dim=0)\n","                    pred = self(input_ids)\n","                    gen = tok.convert_ids_to_tokens(\n","                        torch.argmax(\n","                            pred,\n","                            dim=-1).squeeze().numpy().tolist())[-1]\n","                    if gen == EOS:\n","                        break\n","                    a += gen.replace('▁', ' ')\n","                return a.strip()\n","\n","model = KoGPT2Comment.load_from_checkpoint('model_chp/model_-last.ckpt')\n","moon_comment = ''\n","max_comment = ''\n","comment = ''\n","for sent in keysents:\n","  comment = model.comment(sent)\n","  if(comment[-1] is not '?' and (not '.' or not '!')):\n","        comment = comment + '.'\n","  if(len(max_comment)<=len(comment)):\n","        max_comment = comment\n","  if(len(comment)>6 and '?' not in comment and '저' not in comment):\n","        moon_comment = comment\n","        break\n","if(moon_comment is ''):\n","  moon_comment = max_comment\n","print(moon_comment)\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"comment_bot.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":0}
